<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>cv on #a5ebec</title>
    <link>https://blog.5ebec.dev/tags/cv/</link>
    <description>Recent content in cv on #a5ebec</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Thu, 24 Oct 2019 08:04:31 +0000</lastBuildDate>
    
	<atom:link href="https://blog.5ebec.dev/tags/cv/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[論文読み] How Do Humans Sketch Objects? </title>
      <link>https://blog.5ebec.dev/posts/%E8%AB%96%E6%96%87%E8%AA%AD%E3%81%BF-how-do-humans-sketch-objects/</link>
      <pubDate>Thu, 24 Oct 2019 08:04:31 +0000</pubDate>
      
      <guid>https://blog.5ebec.dev/posts/%E8%AB%96%E6%96%87%E8%AA%AD%E3%81%BF-how-do-humans-sketch-objects/</guid>
      <description>How Do Humans Sketch Objects? Mathias Eitz, James Hays, Marc Alexa SIGGRAPH, 2012 PDF Website video
  What it is about 人間のスケッチのクラシフィケーション
※ スケッチ = 熟練者が描いたものではない抽象的な絵(ピクトグラフ)
Why it is worthy researching  人間が物体をどのようにスケッチし、そのようなスケッチを人間とコンピューターがどれだけうまく認識できるかについての正式な研究はこれまでなかった．人間のスケッチに対する最初の大規模な調査．
 Amazon Mechanical Turk というクラウドソーシングサービスを利用してデータセットを生成している． 人間の認識精度も Amazon Mechanical Turk を用いて得ている． 学習モデルとしてkNN法，SVMを使用  Key idea データセット 
 250のカテゴリ:
日常生活で見かける，形状だけで認識可能なオブジェクトを網羅している
 20,000個のスケッチ:
スケッチされたストロークの空間的パラメータと時間的順序を保存する
(ただし，この研究では時間的順序は使用されていない)
1カテゴリ毎に80個，合計20,000個のスケッチ
  How it is validated (experimental setup and results)  56％の精度で未知のスケッチを識別することができている</description>
    </item>
    
    <item>
      <title>[論文読み] Shape from Shading through Shape Evolution</title>
      <link>https://blog.5ebec.dev/posts/shape-from-shading-through-shape-evolution/</link>
      <pubDate>Thu, 29 Aug 2019 22:50:01 +0000</pubDate>
      
      <guid>https://blog.5ebec.dev/posts/shape-from-shading-through-shape-evolution/</guid>
      <description>Shape from Shading through Shape Evolution Dawei Yang, Jia Deng CVPR, 2018 arXiv, SemanticScholar  What it is about 実画像の Shape-from-Shading を DNN に学習させる際のデータとして，単純なプリミティブ (球，立方体，等) を用いて作成された 3D データを用いる手法を提案．
Why it is worthy researching 既存手法では全て人手で作成されたデータを用いていた．
提案手法ではシンプルなプリミティブを組み合わせて複雑な形状のデータセットを適宜作成して， DNN の学習を行うことでデータ不足を解決する． トレーニングに外部データセットを用いることなく，実画像に対する Shape-from-Shading において State-of-the-Art (SoTA) を達成．
Key idea Shape Representation 初期形状は球，円柱，立方体，円錐の４つの形状で構成されており，それらは以下の函数で表すことができる．

Computation graph で表現すると以下のようになる．

形状変換(平行移動，回転，拡大縮小)

形状結合

進化アルゴリズム 形状変換と形状結合を繰り返すことでより複雑な形状へ進化させる．
Computation graph が大きくなりすぎないように（制約がなければ平均計算コストは指数関数的に増加する），計算回数が線形になるようにグラフの成長を制限する．また，形状結合前後で変化がほぼ無いケースを検出し排除する等，進化が遅くならないようにする．
バリデーションを実画像で行うため，実画像が持つ形状とかけ離れた形状を持つトレーニングデータは捨てられる．

shape-from-shading ネットワークは Stacked Hourglass Network を使用している．</description>
    </item>
    
    <item>
      <title>[論文読み] Neural Inverse Rendering of an Indoor Scene From a Single Image</title>
      <link>https://blog.5ebec.dev/posts/neural-inverse-rendering-of-an-indoor-scene-from-a-single-image/</link>
      <pubDate>Fri, 17 May 2019 06:52:00 +0000</pubDate>
      
      <guid>https://blog.5ebec.dev/posts/neural-inverse-rendering-of-an-indoor-scene-from-a-single-image/</guid>
      <description>Neural Inverse Rendering of an Indoor Scene from a Single Image Soumyadip Sengupta, Jinwei Gu, Kihwan Kim, Guilin Liu, David W. Jacobs, Jan Kautz CVPR, 2019 arXiv, SemanticScholar  What it is about 単一画像からの屋内シーンのニューラルインバースレンダリング
インバースレンダリングとは 画像からシーンの物理的属性
 物体形状(表面法線ベクトル) 反射特性(アルベド) 光源分布(照明マップ)  を推定することを目的としている．
Why it is worthy researching 屋内シーンの単一画像を，Inverse Rendering Network (IRN)を用いて
 アルベド 表面法線ベクトル 照明の環境マップ  の3つの属性に分解する．
今までの手法では，主に単一のオブジェクトに対して，またはシーン属性の１つのみを解決するものだった．
本稿では，屋内シーンの単一画像に対してそれらのシーン属性を同時に解くことができる事ができる．
また，SUNCG-PBRという名のデータセットを作成している．
このデータセットは以前のデータセットを大幅に改善したもの
 鏡面反射を仮定したシーン 拡散反射を仮定したシーン ground truth depth surface normals albedo Phong model parameters semantic segmentation glossiness segmentation  以前のデータセットと比べてより写実的でノイズが少ないのが特徴</description>
    </item>
    
  </channel>
</rss>